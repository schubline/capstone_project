# Overview: Current Landscape of Online Reviews
_Author: Schubert H. Laforest_

## The Situation

> 82% of adults consult online reviews before buying something for the first time, 40% always do [1]

>  A one-star increase in Yelp rating leads to a 5-9 percent increase in revenue [7]


Questions: Do user generate reviews actually reflect "quality"?

In general marketing contexts, when we see an ad, we have our "guard" up - we know we're being sold to, hence making it more difficult for us to be persuaded. However, when we get feedback from ordinary people without a profit motive, the opinion seems more "genuine", and our guard goes down. This reality is one of the main reasons why online reviews can be so powerful. That being said, do reviews actually aid consumers in making better purchasing decisions?

[1]: FERNBACH et all did a study where they analyzed 1272 products across 120 vertically differentiated product categories, comparing and contrasting their Amazon Reviews and their Consumer Report Scores. Here were the main takeaways:
- They observed a lack convergence with Consumer Reports scores,
the most commonly used measure of objective quality in the consumer behavior
literature
- The Amazon review scores were often based on insufficient sample sizes which limits their informativeness
- The ratings do not predict resale prices in the used-product marketplace. One would expect a product with a 5 star rating to have a higher resale value than a product with 4 star rating. There was virtually no statistically significant relationship.
- The higher for more expensive products and premium brands, controlling for
Consumer Reports scores.
- When forming quality inferences and purchase intentions, consumers heavily weight the average rating compared to other cues for quality like price and the number of ratings
- Consumers fail to moderate their reliance on the average user rating as a function of sample size sufficiency
- Consumers’ trust in the average user rating as a cue for objective quality appears to be based on an “illusion of validity.”

> There is a low correspondence (~57% of the time) between Amazon stars and Consumer Reports ratings.

Other Takeaways:
- Online reviews are subject to many biases:
  1) a more expensive product/service is viewed as being of better quality.
  2) Reviewers are more likely to rate products with better display pictures and brand recognition more positively
  3) "Show-off Bias"

## The Breakdown

## What does this mean?





### Sources
[Navigating by the Stars: Investigating the Actual and Perceived Validity of Online User Ratings](https://www.colorado.edu/business/sites/default/files/attached-files/jcr_2016_de_langhe_fernbach_lichtenstein_0.pdf)

[What we know and Don't Kow About Online Word-Of-Mouth: A Systematic Review and Synthesus of the Literature](268002121029092115114026104120098072036003073064003042025005116081029126095113006076041124028101103055098076030120122119127090051045002046054000109089025109029117127088020020066064104074027083098103109070109079100124004124001029099106083100068111124029)


[Palmer v. KlearGear.com](https://www.citizen.org/our-work/litigation/cases/palmer-v-kleargearcom)

[H.R.5111 - Consumer Review Fairness Act of 2016](https://www.congress.gov/bill/114th-congress/house-bill/5111)

[Understanding the Consumer Review Fairness Act of 2016](089119105064005114099020108065092124022046039021042055064086124096098076117111097028063033000008109016026092119030097024120091006041062046036010086025115119112122005009028067109084122016012114073107120023092028126028114103100002020016077111081070123)

[Doctored Reviews](https://doctoredreviews.com)

[Reviews, Reputation, and Revenue: The Case of Yelp.com](https://www.hbs.edu/faculty/Publication%20Files/12-016_a7e4a5a2-03f9-490d-b093-8f951238dba2.pdf)
