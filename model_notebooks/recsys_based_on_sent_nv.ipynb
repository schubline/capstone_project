{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nevada Recsys based on Sentiment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will be creating various Recommender systems, taking different approaches based on Yelp review star ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import sklearn\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse.linalg import svds\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/schubert/DSI/capstone_project/model_notebooks/sent_rec_data_nv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>xP1IYu2eGfxMWV9tjrurIw</td>\n",
       "      <td>\"Delmonico Steakhouse\"</td>\n",
       "      <td>0.405723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>oFyOUOeGTRZhFPF9uTqrTQ</td>\n",
       "      <td>\"Delmonico Steakhouse\"</td>\n",
       "      <td>0.284375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>2aeNFntqY2QDZLADNo8iQQ</td>\n",
       "      <td>\"Delmonico Steakhouse\"</td>\n",
       "      <td>0.383492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>gmPP4YFrgYsYQqPYokMgFA</td>\n",
       "      <td>\"Delmonico Steakhouse\"</td>\n",
       "      <td>0.310536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>9bxdPvAhP6cuipD5s2UnCg</td>\n",
       "      <td>\"Delmonico Steakhouse\"</td>\n",
       "      <td>0.272811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                 user_id                    name  \\\n",
       "0  --9e1ONYQuAa-CB_Rrw7Tw  xP1IYu2eGfxMWV9tjrurIw  \"Delmonico Steakhouse\"   \n",
       "1  --9e1ONYQuAa-CB_Rrw7Tw  oFyOUOeGTRZhFPF9uTqrTQ  \"Delmonico Steakhouse\"   \n",
       "2  --9e1ONYQuAa-CB_Rrw7Tw  2aeNFntqY2QDZLADNo8iQQ  \"Delmonico Steakhouse\"   \n",
       "3  --9e1ONYQuAa-CB_Rrw7Tw  gmPP4YFrgYsYQqPYokMgFA  \"Delmonico Steakhouse\"   \n",
       "4  --9e1ONYQuAa-CB_Rrw7Tw  9bxdPvAhP6cuipD5s2UnCg  \"Delmonico Steakhouse\"   \n",
       "\n",
       "   sentiment_score  \n",
       "0         0.405723  \n",
       "1         0.284375  \n",
       "2         0.383492  \n",
       "3         0.310536  \n",
       "4         0.272811  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](recsys_workflow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# users: 357521\n",
      "# users with at least 2 interactions: 146664\n"
     ]
    }
   ],
   "source": [
    "users_interactions_count_df = data.groupby(['user_id', 'name']).size().groupby('user_id').size()\n",
    "print('# users: %d' % len(users_interactions_count_df))\n",
    "users_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 2].reset_index()[['user_id']]\n",
    "print('# users with at least 2 interactions: %d' % len(users_with_enough_interactions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recsys Train-Test-Split\n",
    "train_data, test_data = train_test_split(data,\n",
    "                                   #stratify=data['sentiment_score'], # we have imbalanced classes, re: J-shaped distribution\n",
    "                                   test_size=0.20,\n",
    "                                   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data: 831640\n",
      "Size of test data: 207911\n"
     ]
    }
   ],
   "source": [
    "print('Size of training data: %d' % len(train_data))\n",
    "print('Size of test data: %d' % len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top N Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing by user_id  to speed up the searches during evaluation\n",
    "data_indexed = data.set_index('user_id')\n",
    "train_indexed = train_data.set_index('user_id')\n",
    "test_indexed = test_data.set_index('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_reviwed_restaurants(user_id, data):\n",
    "    '''\n",
    "    Fuction that matches user_id to the restaurants they've reviewed\n",
    "    ----\n",
    "    Parameters:\n",
    "    user_id: corresponding unique user id \n",
    "    data: pandas dataframe containing business_id, name, user_id, stars\n",
    "    '''\n",
    "    reviewed_restaurants = data.loc[user_id]['name']\n",
    "    return set(reviewed_restaurants if type(reviewed_restaurants) == pd.Series else [reviewed_restaurants])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top-N accuracy metrics consts\n",
    "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n",
    "\n",
    "class RecsysEvaluator:\n",
    "\n",
    "\n",
    "    def businesses_not_reviewed_sample(self, user_id, sample_size, seed=42):\n",
    "        reviewed_restaurants = find_reviwed_restaurants(user_id, data_indexed)\n",
    "        all_restaurants = set(data['name'])\n",
    "        non_reviewed_restaurants = all_restaurants - reviewed_restaurants\n",
    "\n",
    "        random.seed(seed)\n",
    "        non_reviewed_restaurants_sample = random.sample(non_reviewed_restaurants, sample_size)\n",
    "        return set(non_reviewed_restaurants_sample)\n",
    "\n",
    "    def _check_hit_top_n(self, name, recommended_restaurants, topn):        \n",
    "            try:\n",
    "                index = next(i for i, c in enumerate(recommended_restaurants) if c == name)\n",
    "            except:\n",
    "                index = -1\n",
    "            hit = int(index in range(0, topn))\n",
    "            return hit, index\n",
    "\n",
    "    def evaluate_model_for_reviewer(self, model, user_id):\n",
    "        # Getting the items in test set\n",
    "        reviewed_restaurants_testset = test_indexed.loc[user_id]\n",
    "        if type(reviewed_restaurants_testset['name']) == pd.Series:\n",
    "            person_reviewed_restaurant_testset = set(reviewed_restaurants_testset['name'])\n",
    "        else:\n",
    "            person_reviewed_restaurant_testset = set(reviewed_restaurants_testset['name'])  \n",
    "        reviewed_restaurant_count_testset = len(reviewed_restaurants_testset) \n",
    "\n",
    "        #Getting a ranked recommendation list from a model for a given user\n",
    "        person_recs_df = model.recommend_items(user_id, \n",
    "                                               restaurants_to_ignore = find_reviwed_restaurants(user_id,\n",
    "                                                                                                data_indexed),\n",
    "                                               topn=10000000000)\n",
    "\n",
    "        hits_at_2_count = 0\n",
    "        hits_at_3_count = 0\n",
    "        #For each item the user has interacted in test set\n",
    "        for item_id in person_reviewed_restaurant_testset:\n",
    "            #Getting a random sample (100) items the user has not interacted \n",
    "            #(to represent items that are assumed to be no relevant to the user)\n",
    "            non_reviewed_restaurants_sample = self.businesses_not_reviewed_sample(user_id, \n",
    "                                                                          sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS, \n",
    "                                                                          seed=42)\n",
    "\n",
    "            #Combining the current interacted item with the 100 random items\n",
    "            restaurants_to_filter_recs = non_reviewed_restaurants_sample.union(set([item_id]))\n",
    "\n",
    "            #Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n",
    "            valid_recs_df = person_recs_df[person_recs_df['name'].isin(restaurants_to_filter_recs)]                    \n",
    "            valid_recs = valid_recs_df['name'].values\n",
    "            \n",
    "            #Verifying if the current interacted item is among the Top-N recommended items\n",
    "            hit_at_2, index_at_2 = self._check_hit_top_n(item_id, valid_recs, 2)\n",
    "            hits_at_2_count += hit_at_2\n",
    "            hit_at_3, index_at_3 = self._check_hit_top_n(item_id, valid_recs, 3)\n",
    "            hits_at_3_count += hit_at_3\n",
    "\n",
    "        #Recall is the rate of the interacted items that are ranked among the Top-N recommended items, \n",
    "        #when mixed with a set of non-relevant items\n",
    "        recall_at_2 = hits_at_2_count / float(reviewed_restaurant_count_testset)\n",
    "        recall_at_3 = hits_at_3_count / float(reviewed_restaurant_count_testset)\n",
    "\n",
    "        person_metrics = {'hits@2_count':[hits_at_2_count], \n",
    "                          'hits@3_count':[hits_at_3_count], \n",
    "                          'interacted_count': [reviewed_restaurant_count_testset],\n",
    "                          'recall@2': [recall_at_2],\n",
    "                          'recall@3': [recall_at_3]}\n",
    "        return person_metrics\n",
    "\n",
    "    def evaluate_model(self, model):\n",
    "        #print('Running evaluation for users')\n",
    "        reviewers_metrics = []\n",
    "        for idx, user_id in enumerate(list(test_indexed.index.unique().values)):\n",
    "            #if idx % 100 == 0 and idx > 0:\n",
    "            #    print('%d users processed' % idx)\n",
    "            reviewer_metrics = self.evaluate_model_for_reviewer(model, user_id)  \n",
    "            reviewer_metrics['_user_id'] = user_id\n",
    "            reviewers_metrics.append(reviewer_metrics)\n",
    "        print('%d users processed' % idx)\n",
    "\n",
    "        detailed_results_df = pd.DataFrame(reviewer_metrics) \\\n",
    "                            .sort_values('interacted_count', ascending=False)\n",
    "        \n",
    "        global_recall_at_2 = detailed_results_df['hits@2_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        global_recall_at_3 = detailed_results_df['hits@3_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        \n",
    "        global_metrics = {'modelName': model.get_model_name(),\n",
    "                          'recall@2': global_recall_at_2,\n",
    "                          'recall@3': global_recall_at_3}    \n",
    "        return global_metrics, detailed_results_df\n",
    "    \n",
    "recsys_evaluator = RecsysEvaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popularity Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Golden Bar &amp; Restaurant Equipment\"</td>\n",
       "      <td>0.669444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"6500 Tavern\"</td>\n",
       "      <td>0.631877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Takeria Puebla\"</td>\n",
       "      <td>0.608333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"El Triunfo Restaurant\"</td>\n",
       "      <td>0.599421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"T.I.G. BBQ\"</td>\n",
       "      <td>0.589494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Pop N' Sons\"</td>\n",
       "      <td>0.577566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Tacos Los Parados\"</td>\n",
       "      <td>0.569158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Sleepy Wilson's Barbecue\"</td>\n",
       "      <td>0.547558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Husongs Cantina\"</td>\n",
       "      <td>0.542396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Firelight Barn\"</td>\n",
       "      <td>0.536445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name  sentiment_score\n",
       "0  \"Golden Bar & Restaurant Equipment\"         0.669444\n",
       "1                        \"6500 Tavern\"         0.631877\n",
       "2                     \"Takeria Puebla\"         0.608333\n",
       "3              \"El Triunfo Restaurant\"         0.599421\n",
       "4                         \"T.I.G. BBQ\"         0.589494\n",
       "5                        \"Pop N' Sons\"         0.577566\n",
       "6                  \"Tacos Los Parados\"         0.569158\n",
       "7           \"Sleepy Wilson's Barbecue\"         0.547558\n",
       "8                    \"Husongs Cantina\"         0.542396\n",
       "9                     \"Firelight Barn\"         0.536445"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant_popularity = data.groupby('name')['sentiment_score'].mean().sort_values(ascending=False).reset_index()\n",
    "restaurant_popularity.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PopularityRecommender:\n",
    "    \n",
    "    MODEL_NAME = 'Popularity'\n",
    "    \n",
    "    def __init__(self, restaurant_popularity, items_df=None):\n",
    "        self.restaurant_popularity = restaurant_popularity\n",
    "        self.items_df = items_df\n",
    "        \n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "        \n",
    "    def recommend_items(self, user_id, restaurants_to_ignore=[], topn=10, verbose=False):\n",
    "        # Recommend the more popular items that the user hasn't seen yet.\n",
    "        recommendations_df = self.restaurant_popularity[~self.restaurant_popularity['name'].isin(restaurants_to_ignore)] \\\n",
    "                               .sort_values('stars', ascending = False) \\\n",
    "                               .head(topn)\n",
    "\n",
    "        if verbose:\n",
    "            if self.items_df is None:\n",
    "                raise Exception('\"items_df\" is required in verbose mode')\n",
    "\n",
    "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n",
    "                                                          left_on = 'contentId', \n",
    "                                                          right_on = 'contentId')[['eventStrength', 'contentId', 'title', 'url', 'lang']]\n",
    "\n",
    "\n",
    "        return recommendations_df\n",
    "    \n",
    "popularity_model = PopularityRecommender(restaurant_popularity, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Popularity recommendation model...\n",
      "906 users processed\n",
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Popularity', 'recall@2': 0.0, 'recall@3': 0.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hits@2_count</th>\n",
       "      <th>hits@3_count</th>\n",
       "      <th>interacted_count</th>\n",
       "      <th>recall@2</th>\n",
       "      <th>recall@3</th>\n",
       "      <th>_user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>q4-Nvtr-FlHxAZu66vm-ig</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hits@2_count  hits@3_count  interacted_count  recall@2  recall@3  \\\n",
       "0             0             0                 3       0.0       0.0   \n",
       "\n",
       "                 _user_id  \n",
       "0  q4-Nvtr-FlHxAZu66vm-ig  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Evaluating Popularity recommendation model...')\n",
    "pop_global_metrics, pop_detailed_results_df = recsys_evaluator.evaluate_model(popularity_model)\n",
    "print('\\nGlobal metrics:\\n%s' % pop_global_metrics)\n",
    "pop_detailed_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7p4mOmAl0X1P-ACgLcH2Yg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying something different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate, KFold, GridSearchCV\n",
    "from surprise import BaselineOnly, NormalPredictor, accuracy\n",
    "from surprise import Reader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to dataset file\n",
    "# file_path = os.path.expanduser(\"/home/schubert/DSI/capstone_project/model_notebooks/star_rec_data_nv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>xP1IYu2eGfxMWV9tjrurIw</td>\n",
       "      <td>\"Delmonico Steakhouse\"</td>\n",
       "      <td>0.405723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>oFyOUOeGTRZhFPF9uTqrTQ</td>\n",
       "      <td>\"Delmonico Steakhouse\"</td>\n",
       "      <td>0.284375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>2aeNFntqY2QDZLADNo8iQQ</td>\n",
       "      <td>\"Delmonico Steakhouse\"</td>\n",
       "      <td>0.383492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>gmPP4YFrgYsYQqPYokMgFA</td>\n",
       "      <td>\"Delmonico Steakhouse\"</td>\n",
       "      <td>0.310536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>9bxdPvAhP6cuipD5s2UnCg</td>\n",
       "      <td>\"Delmonico Steakhouse\"</td>\n",
       "      <td>0.272811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                 user_id                    name  \\\n",
       "0  --9e1ONYQuAa-CB_Rrw7Tw  xP1IYu2eGfxMWV9tjrurIw  \"Delmonico Steakhouse\"   \n",
       "1  --9e1ONYQuAa-CB_Rrw7Tw  oFyOUOeGTRZhFPF9uTqrTQ  \"Delmonico Steakhouse\"   \n",
       "2  --9e1ONYQuAa-CB_Rrw7Tw  2aeNFntqY2QDZLADNo8iQQ  \"Delmonico Steakhouse\"   \n",
       "3  --9e1ONYQuAa-CB_Rrw7Tw  gmPP4YFrgYsYQqPYokMgFA  \"Delmonico Steakhouse\"   \n",
       "4  --9e1ONYQuAa-CB_Rrw7Tw  9bxdPvAhP6cuipD5s2UnCg  \"Delmonico Steakhouse\"   \n",
       "\n",
       "   sentiment_score  \n",
       "0         0.405723  \n",
       "1         0.284375  \n",
       "2         0.383492  \n",
       "3         0.310536  \n",
       "4         0.272811  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we're loading a custom dataset, we need to define a reader. In the\n",
    "# movielens-100k dataset, each line has the following format:\n",
    "# 'user item rating timestamp', separated by '\\t' characters.\n",
    "# reader = Reader(line_format='business_id ; name ; user_id ; stars', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.load_from_df(data[['name', 'user_id', 'sentiment_score']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluating RMSE, MAE of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.7839  0.7837  0.7843  0.7848  0.7835  0.7840  0.0005  \n",
      "MAE (testset)     0.7485  0.7484  0.7488  0.7493  0.7479  0.7486  0.0005  \n",
      "Fit time          4.49    4.75    4.89    4.81    4.72    4.73    0.13    \n",
      "Test time         1.82    1.80    1.49    1.81    1.41    1.67    0.18    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': (4.492543458938599,\n",
       "  4.750595331192017,\n",
       "  4.889585018157959,\n",
       "  4.810168504714966,\n",
       "  4.719566345214844),\n",
       " 'test_mae': array([0.74853507, 0.74841616, 0.74875461, 0.74931724, 0.74790708]),\n",
       " 'test_rmse': array([0.78390071, 0.78374458, 0.78429183, 0.78480169, 0.78347207]),\n",
       " 'test_time': (1.8231899738311768,\n",
       "  1.7973172664642334,\n",
       "  1.4912734031677246,\n",
       "  1.813295841217041,\n",
       "  1.4105546474456787)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(BaselineOnly(), data, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': (0.6187007427215576, 0.8592300415039062),\n",
       " 'test_mae': array([0.7485425 , 0.74871039]),\n",
       " 'test_rmse': array([0.78407404, 0.78409467]),\n",
       " 'test_time': (4.108623266220093, 4.116459369659424)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(NormalPredictor(), data, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7842\n",
      "RMSE: 0.7838\n",
      "RMSE: 0.7841\n"
     ]
    }
   ],
   "source": [
    "# define a cross-validation iterator\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "algo = SVD()\n",
    "\n",
    "for trainset, testset in kf.split(data):\n",
    "\n",
    "    # train and test algorithm.\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    # Compute and print Root Mean Squared Error\n",
    "    accuracy.rmse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n",
    "              'reg_all': [0.4, 0.6]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7f2ecce23208>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now use the algorithm that yields the best rmse:\n",
    "algo = gs.best_estimator['rmse']\n",
    "algo.fit(data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_rmse</th>\n",
       "      <th>split1_test_rmse</th>\n",
       "      <th>split2_test_rmse</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "      <th>std_test_rmse</th>\n",
       "      <th>rank_test_rmse</th>\n",
       "      <th>split0_test_mae</th>\n",
       "      <th>split1_test_mae</th>\n",
       "      <th>split2_test_mae</th>\n",
       "      <th>mean_test_mae</th>\n",
       "      <th>std_test_mae</th>\n",
       "      <th>rank_test_mae</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_test_time</th>\n",
       "      <th>std_test_time</th>\n",
       "      <th>params</th>\n",
       "      <th>param_n_epochs</th>\n",
       "      <th>param_lr_all</th>\n",
       "      <th>param_reg_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.268387</td>\n",
       "      <td>1.265663</td>\n",
       "      <td>1.267009</td>\n",
       "      <td>1.267020</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>7</td>\n",
       "      <td>1.040979</td>\n",
       "      <td>1.037885</td>\n",
       "      <td>1.039616</td>\n",
       "      <td>1.039493</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>6</td>\n",
       "      <td>9.864846</td>\n",
       "      <td>0.056042</td>\n",
       "      <td>2.638301</td>\n",
       "      <td>0.272984</td>\n",
       "      <td>{'n_epochs': 5, 'lr_all': 0.002, 'reg_all': 0.4}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.274219</td>\n",
       "      <td>1.271427</td>\n",
       "      <td>1.272727</td>\n",
       "      <td>1.272791</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>8</td>\n",
       "      <td>1.048038</td>\n",
       "      <td>1.044812</td>\n",
       "      <td>1.046615</td>\n",
       "      <td>1.046488</td>\n",
       "      <td>0.001320</td>\n",
       "      <td>8</td>\n",
       "      <td>9.491911</td>\n",
       "      <td>0.012535</td>\n",
       "      <td>2.497279</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>{'n_epochs': 5, 'lr_all': 0.002, 'reg_all': 0.6}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.258668</td>\n",
       "      <td>1.256008</td>\n",
       "      <td>1.257297</td>\n",
       "      <td>1.257324</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>2</td>\n",
       "      <td>1.031735</td>\n",
       "      <td>1.028620</td>\n",
       "      <td>1.030123</td>\n",
       "      <td>1.030159</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>2</td>\n",
       "      <td>9.685466</td>\n",
       "      <td>0.142121</td>\n",
       "      <td>2.497078</td>\n",
       "      <td>0.292577</td>\n",
       "      <td>{'n_epochs': 5, 'lr_all': 0.005, 'reg_all': 0.4}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.265265</td>\n",
       "      <td>1.262640</td>\n",
       "      <td>1.263859</td>\n",
       "      <td>1.263921</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>5</td>\n",
       "      <td>1.039891</td>\n",
       "      <td>1.036772</td>\n",
       "      <td>1.038325</td>\n",
       "      <td>1.038329</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>5</td>\n",
       "      <td>9.590522</td>\n",
       "      <td>0.135125</td>\n",
       "      <td>2.511860</td>\n",
       "      <td>0.338188</td>\n",
       "      <td>{'n_epochs': 5, 'lr_all': 0.005, 'reg_all': 0.6}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.260555</td>\n",
       "      <td>1.257970</td>\n",
       "      <td>1.259228</td>\n",
       "      <td>1.259251</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>4</td>\n",
       "      <td>1.033356</td>\n",
       "      <td>1.030274</td>\n",
       "      <td>1.032089</td>\n",
       "      <td>1.031906</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>3</td>\n",
       "      <td>17.901575</td>\n",
       "      <td>0.216289</td>\n",
       "      <td>2.855000</td>\n",
       "      <td>0.072783</td>\n",
       "      <td>{'n_epochs': 10, 'lr_all': 0.002, 'reg_all': 0.4}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split0_test_rmse  split1_test_rmse  split2_test_rmse  mean_test_rmse  \\\n",
       "0          1.268387          1.265663          1.267009        1.267020   \n",
       "1          1.274219          1.271427          1.272727        1.272791   \n",
       "2          1.258668          1.256008          1.257297        1.257324   \n",
       "3          1.265265          1.262640          1.263859        1.263921   \n",
       "4          1.260555          1.257970          1.259228        1.259251   \n",
       "\n",
       "   std_test_rmse  rank_test_rmse  split0_test_mae  split1_test_mae  \\\n",
       "0       0.001112               7         1.040979         1.037885   \n",
       "1       0.001141               8         1.048038         1.044812   \n",
       "2       0.001086               2         1.031735         1.028620   \n",
       "3       0.001072               5         1.039891         1.036772   \n",
       "4       0.001055               4         1.033356         1.030274   \n",
       "\n",
       "   split2_test_mae  mean_test_mae  std_test_mae  rank_test_mae  mean_fit_time  \\\n",
       "0         1.039616       1.039493      0.001266              6       9.864846   \n",
       "1         1.046615       1.046488      0.001320              8       9.491911   \n",
       "2         1.030123       1.030159      0.001272              2       9.685466   \n",
       "3         1.038325       1.038329      0.001273              5       9.590522   \n",
       "4         1.032089       1.031906      0.001265              3      17.901575   \n",
       "\n",
       "   std_fit_time  mean_test_time  std_test_time  \\\n",
       "0      0.056042        2.638301       0.272984   \n",
       "1      0.012535        2.497279       0.302326   \n",
       "2      0.142121        2.497078       0.292577   \n",
       "3      0.135125        2.511860       0.338188   \n",
       "4      0.216289        2.855000       0.072783   \n",
       "\n",
       "                                              params  param_n_epochs  \\\n",
       "0   {'n_epochs': 5, 'lr_all': 0.002, 'reg_all': 0.4}               5   \n",
       "1   {'n_epochs': 5, 'lr_all': 0.002, 'reg_all': 0.6}               5   \n",
       "2   {'n_epochs': 5, 'lr_all': 0.005, 'reg_all': 0.4}               5   \n",
       "3   {'n_epochs': 5, 'lr_all': 0.005, 'reg_all': 0.6}               5   \n",
       "4  {'n_epochs': 10, 'lr_all': 0.002, 'reg_all': 0.4}              10   \n",
       "\n",
       "   param_lr_all  param_reg_all  \n",
       "0         0.002            0.4  \n",
       "1         0.002            0.6  \n",
       "2         0.005            0.4  \n",
       "3         0.005            0.6  \n",
       "4         0.002            0.4  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame.from_dict(gs.cv_results)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = SVD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.3344  1.2859  1.3148  1.2859  1.3055  1.3053  0.0184  \n",
      "MAE (testset)     1.1064  1.0571  1.0919  1.0597  1.0814  1.0793  0.0188  \n",
      "Fit time          0.24    0.23    0.24    0.24    0.27    0.24    0.02    \n",
      "Test time         0.01    0.01    0.01    0.01    0.01    0.01    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': (0.2445533275604248,\n",
       "  0.2275230884552002,\n",
       "  0.23551177978515625,\n",
       "  0.2358841896057129,\n",
       "  0.2743501663208008),\n",
       " 'test_mae': array([1.10641844, 1.05713763, 1.09192113, 1.05970146, 1.0814054 ]),\n",
       " 'test_rmse': array([1.33441692, 1.28590703, 1.31476337, 1.28588078, 1.30546843]),\n",
       " 'test_time': (0.0077037811279296875,\n",
       "  0.006069660186767578,\n",
       "  0.009871244430541992,\n",
       "  0.006154060363769531,\n",
       "  0.00622105598449707)}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
